{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/Hackathon_bureau_data_50000.csv\")\n",
    "\n",
    "# print(df.info())    \n",
    "# print(df.describe())\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "df = df.dropna(subset=['target_income'])\n",
    "df = df.drop_duplicates()\n",
    "df = df.apply(lambda x: x.str.strip().str.lower() if x.dtype == 'object' else x)\n",
    "\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    important_numeric = ['age','var_0', 'var_1','var_2', 'var_3', 'var_13', 'var_14']\n",
    "    # Only create interactions between important features\n",
    "    for i in range(len(important_numeric)):\n",
    "        for j in range(i+1, len(important_numeric)):\n",
    "            col1, col2 = important_numeric[i], important_numeric[j]\n",
    "            if col1 in df.columns and col2 in df.columns:\n",
    "                df[f'{col1}_{col2}_interaction'] = df[col1] * df[col2]\n",
    "    # Polynomial features\n",
    "    for col in important_numeric:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_squared'] = df[col] ** 2\n",
    "    return df\n",
    "\n",
    "# Replace rare categories with 'other'\n",
    "def reduce_cardinality(df, threshold=0.01):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        freqs = df[col].value_counts(normalize=True)\n",
    "        rare_labels = freqs[freqs < threshold].index\n",
    "        df[col] = df[col].apply(lambda x: 'other' if x in rare_labels else x)\n",
    "    return df\n",
    "\n",
    "X = df.drop(columns=['target_income'])\n",
    "y = df['target_income']\n",
    "\n",
    "X = reduce_cardinality(X)\n",
    "df = engineer_features(df)\n",
    "\n",
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include='number').columns.tolist()   #0.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder , StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso , Ridge\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"selector\", SelectFromModel(lasso))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression , mutual_info_regression\n",
    "\n",
    "\n",
    "# feature_selector = SelectKBest(f_regression, k=1000)  # Select top 1000 features\n",
    "\n",
    "\n",
    "# model = LGBMRegressor(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=4,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create stacking model\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('lgbm', lgbm),\n",
    "        ('xgb', xgb)\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split , RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    # (\"model\", model)\n",
    "    (\"feature_selector\", SelectKBest(mutual_info_regression, k=2000)),  # Using mutual_info_regression for better feature selection\n",
    "    (\"model\", stacking_regressor)\n",
    "\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R2: {r2}\")\n",
    "\n",
    "print(\"âœ… Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
