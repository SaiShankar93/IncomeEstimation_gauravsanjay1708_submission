{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, psutil\n",
    "import gc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and sample the dataset (reduce size for dev)\n",
    "try:\n",
    "    df = pd.read_csv(\"data/Hackathon_bureau_data_50000.csv\", encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(\"data/Hackathon_bureau_data_50000.csv\", encoding='latin1')\n",
    "\n",
    "\n",
    "SAMPLE_SIZE = 20000\n",
    "df = df.sample(SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "mem = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"üìä Sampled {SAMPLE_SIZE} rows using ~{mem:.2f} MB RAM\")\n",
    "\n",
    "available_mem = psutil.virtual_memory().available / (1024 ** 2)\n",
    "if mem > 0.3 * available_mem:\n",
    "    raise MemoryError(f\"‚ùå Not enough memory to process {SAMPLE_SIZE} rows safely.\")\n",
    "\n",
    "df = df.dropna(subset=['target_income'])\n",
    "df = df.drop_duplicates()\n",
    "df = df.apply(lambda x: x.str.strip().str.lower() if x.dtype == 'object' else x)\n",
    "gc.collect()\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df['target_income'], kde=True)\n",
    "plt.title('Distribution of Target Income')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', annot=False)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "for col in ['age', 'income', 'credit_score']:\n",
    "    if col in df.columns:\n",
    "        sns.scatterplot(x=col, y='target_income', data=df)\n",
    "        plt.title(f'{col} vs Target Income')\n",
    "        plt.show()\n",
    "\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Feature reduction based on correlation with target\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "target_corr = corr_matrix['target_income'].abs().sort_values(ascending=False)\n",
    "print(\"\\nüîç Top correlated features with target:\")\n",
    "print(target_corr.head(10))\n",
    "\n",
    "# Drop features with low correlation (< 0.01)\n",
    "low_corr_cols = target_corr[target_corr < 0.01].index.tolist()\n",
    "df.drop(columns=low_corr_cols, inplace=True)\n",
    "\n",
    "# %%\n",
    "def reduce_cardinality(df, threshold=0.01):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        freqs = df[col].value_counts(normalize=True)\n",
    "        rare_labels = freqs[freqs < threshold].index\n",
    "        df[col] = df[col].apply(lambda x: 'other' if x in rare_labels else x)\n",
    "    return df\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    important_numeric = ['age', 'income', 'credit_score']\n",
    "    for col in important_numeric:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_squared'] = df[col] ** 2\n",
    "\n",
    "    combos = list(combinations(important_numeric, 2))\n",
    "    for col1, col2 in combos:\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            df[f'{col1}_{col2}_interaction'] = df[col1] * df[col2]\n",
    "\n",
    "    return df\n",
    "\n",
    "X = df.drop(columns=['target_income'])\n",
    "y = df['target_income']  # Removed log1p transformation\n",
    "X = reduce_cardinality(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = engineer_features(X_train)\n",
    "X_test = engineer_features(X_test)\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "numeric_cols = X_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute numeric columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X_train[numeric_cols] = imputer_num.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = imputer_num.transform(X_test[numeric_cols])\n",
    "\n",
    "# Impute categorical columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train[categorical_cols] = imputer_cat.fit_transform(X_train[categorical_cols])\n",
    "X_test[categorical_cols] = imputer_cat.transform(X_test[categorical_cols])\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "selector.fit(X_train[numeric_cols], y_train)\n",
    "feature_scores = pd.Series(selector.scores_, index=numeric_cols).sort_values(ascending=False)\n",
    "\n",
    "# Visualize top features\n",
    "feature_scores.head(30).plot(kind='barh', figsize=(10, 8), title='Top 30 Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Keep only top 30 features\n",
    "top_n = 30\n",
    "selected_numeric_cols = feature_scores.head(top_n).index.tolist()\n",
    "\n",
    "X_train = X_train[selected_numeric_cols + categorical_cols]\n",
    "X_test = X_test[selected_numeric_cols + categorical_cols]\n",
    "\n",
    "# %%\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import time\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=18,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train_final, y_train_final)\n",
    "print(\"‚úÖ Model training completed in\", time.time() - start, \"seconds\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(\"‚úÖ Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
